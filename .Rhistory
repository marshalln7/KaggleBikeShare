if(roll_function()){
total_wins <- total_wins + 1
}
else{
total_losses <- total_losses + 1
}
}
print(total_wins / (total_losses + total_wins))
total_wins <- 0
total_losses <- 0
for (i in 1:10000) {
if(roll_function()){
total_wins <- total_wins + 1
}
else{
total_losses <- total_losses + 1
}
}
print(total_wins / (total_losses + total_wins))
options <- c("Fire!", "No Fire")
weights <- c(0.3, 0.7)
print(sample(options, size = 1, prob = weights))
options <- c("Fire!", "No Fire")
weights <- c(0.3, 0.7)
print(sample(options, size = 1, prob = weights))
options <- c("Fire!", "No Fire")
weights <- c(0.3, 0.7)
print(sample(options, size = 1, prob = weights))
options <- c("Fire!", "No Fire")
weights <- c(0.3, 0.7)
print(sample(options, size = 1, prob = weights))
options <- c("Fire!", "No Fire")
weights <- c(0.3, 0.7)
print(sample(options, size = 1, prob = weights))
options <- c("Fire!", "No Fire")
weights <- c(0.3, 0.7)
print(sample(options, size = 1, prob = weights))
options <- c("Fire!", "No Fire")
weights <- c(0.3, 0.7)
print(sample(options, size = 1, prob = weights))
options <- c("Fire!", "No Fire")
weights <- c(0.3, 0.7)
print(sample(options, size = 1, prob = weights))
options <- c("Fire!", "No Fire")
weights <- c(0.3, 0.7)
fire_function <- function(n){
for (i in 1:n) {
result <- sample(options, size = 1, prob = weights)
print(result)
}
}
fire_function(5)
fire_function(10)
v <- c()
v
repeatable_fire_function <- function(n){
report <- c()
for (i in 1:n) {
result <- sample(options, size = 1, prob = weights)
report <- c(report, result)
}
return(report)
}
repeatable_fire_function()
repeatable_fire_function(2)
repeatable_fire_function(10)
c(1,2) == c(1,2)
sum(c(1,2) == c(1,2))
c(T, T) == T
c(T, T) == F
repeatable_fire_function <- function(n){
report <- c()
for (i in 1:n) {
result <- sample(options, size = 1, prob = weights)
report <- c(report, result)
}
return(report)
}
repeatable_fire_function(4)
options <- c(T, F)
weights <- c(0.3, 0.7)
repeatable_fire_function <- function(n){
report <- c()
for (i in 1:n) {
result <- sample(options, size = 1, prob = weights)
report <- c(report, result)
}
return(report)
}
report <- c()
for (i in 1:1000) {
if(repeatable_fire_function(2) == TRUE
}
repeatable_fire_function()
repeatable_fire_function(4)
options <- c(T, F)
weights <- c(0.3, 0.7)
repeatable_fire_function <- function(n){
report <- c()
for (i in 1:n) {
result <- sample(options, size = 1, prob = weights)
report <- c(report, result)
}
return(report)
}
big_report <- 0
for (i in 1:1000) {
if(sum(repeatable_fire_function(2)) == 1){
big_report <- big_report + 1
}
}
print(big_report/1000)
options <- c(T, F)
weights <- c(0.3, 0.7)
repeatable_fire_function <- function(n){
report <- c()
for (i in 1:n) {
result <- sample(options, size = 1, prob = weights)
report <- c(report, result)
}
return(report)
}
big_report <- 0
for (i in 1:1000) {
if(sum(repeatable_fire_function(5)) >= 3){
big_report <- big_report + 1
}
}
print(big_report/1000)
options <- c(T, F)
weights <- c(0.3, 0.7)
repeatable_fire_function <- function(n){
report <- c()
for (i in 1:n) {
result <- sample(options, size = 1, prob = weights)
report <- c(report, result)
}
return(report)
}
big_report <- 0
for (i in 1:1000) {
if(sum(repeatable_fire_function(2)) == 1){
big_report <- big_report + 1
}
}
print(big_report/1000)
options <- c(T, F)
weights <- c(0.3, 0.7)
repeatable_fire_function <- function(n){
report <- c()
for (i in 1:n) {
result <- sample(options, size = 1, prob = weights)
report <- c(report, result)
}
return(report)
}
big_report <- 0
for (i in 1:1000) {
if(sum(repeatable_fire_function(2)) == 1){
big_report <- big_report + 1
}
}
print(big_report/1000)
options <- c(T, F)
weights <- c(0.3, 0.7)
repeatable_fire_function <- function(n){
report <- c()
for (i in 1:n) {
result <- sample(options, size = 1, prob = weights)
report <- c(report, result)
}
return(report)
}
big_report <- 0
for (i in 1:10000) {
if(sum(repeatable_fire_function(2)) == 1){
big_report <- big_report + 1
}
}
print(big_report/10000)
options <- c(T, F)
weights <- c(0.3, 0.7)
repeatable_fire_function <- function(n){
report <- c()
for (i in 1:n) {
result <- sample(options, size = 1, prob = weights)
report <- c(report, result)
}
return(report)
}
big_report <- 0
for (i in 1:10000) {
if(sum(repeatable_fire_function(5)) >= 3){
big_report <- big_report + 1
}
}
print(big_report/10000)
?tapply
source("Project1bCLT.R")
Draws <- 1000
nrep <- 100
RESULTS <- NULL
for (l in (seq(.5, 2, .5))){
for (k in (c(.5, 1, 3, 5, 7, 9))){
for (n in (c(2, 15, 30, 45, 60))){
for (rep in 1:nrep){
Indiv.results <- CLT(n,k,l,Draws)
RESULTS <- c(RESULTS, Indiv.results)
# print(c(l,k,n))
}
}
}
}
matrix(RESULTS,ncol = 4, byrow = TRUE) -> Weibullmatrix
Weibullmatrix[,4] <= .05
as.data.frame(Weibullmatrix)->Weibullmatrix.df
# Weibullmatrix[33,2] (Row 33 column 2)
average(Weibullmatrix.df)
mean(Weibullmatrix.df)
mean(Weibullmatrix)
View(Weibullmatrix)
mean(Weibullmatrix$V4)
View(Weibullmatrix.df)
View(Weibullmatrix)
mean(Weibullmatrix.df$V4)
mean(Weibullmatrix.df$V1)
mean(Weibullmatrix.df$V4)
qt(0.975, 4)
?tukey
Tukey
library(tidyverse)
?Tukey
# Create a sample data frame
data <- data.frame(
Group = rep(c("A", "B", "C", "D"), each = 25),
Values = c(rnorm(25, mean = 10, sd = 2),
rnorm(25, mean = 12, sd = 2),
rnorm(25, mean = 15, sd = 2),
rnorm(25, mean = 18, sd = 2))
)
# Create a Tukey boxplot
boxplot(Values ~ Group, data = data, outline = FALSE, col = "skyblue", main = "Tukey Boxplot")
?rnorm
# Create a sample data frame
data <- rnorm(1000)
View(Weibullmatrix)
# Create a sample data frame
data <- rnorm(1000)
# Create a Tukey boxplot
boxplot(data = data, outline = FALSE, col = "skyblue", main = "Tukey Boxplot")
# Create a Tukey boxplot
boxplot(x = data, data = data, outline = FALSE, col = "skyblue", main = "Tukey Boxplot")
?boxplot
# Create a Tukey boxplot
boxplot(x = data, outline = FALSE, col = "skyblue", main = "Tukey Boxplot")
data <- rnorm(1000)
# Create a Tukey boxplot
boxplot(x = data, outline = FALSE, col = "skyblue", main = "Tukey Boxplot")
qnorm(0.25)
qnorm(0.75)
pnorm(-3.6863)
pnorm(-3.6863)*2
pnorm(-2) *2
cancer_data <- read_table("https://tofu.byu.edu/stat230/cancer.txt")
View(cancer_data)
cancer_data %>%
group_by("type") %>%
summarize()
cancer_data %>%
group_by(type) %>%
summarize()
?summarize
cancer_data %>%
group_by(type) %>%
print(summarize())
cancer_data %>%
group_by(type) %>%
summarize(mean(days), sd(days))
boxplot(cancer_data$days ~ type)
boxplot(cancer_data$days ~ cancer_data$type)
cancer_data %>%
group_by(type) %>%
summarize(mean(days), sd(days)) %>%
boxplot(cancer_data$days)
library(tidyverse)
cancer_data <- read_table("https://tofu.byu.edu/stat230/cancer.txt")
cancer_data %>%
group_by(type) %>%
summarize(mean(days), sd(days)) %>%
boxplot(cancer_data$days ~ cancer_data$type)
library(tidyverse)
cancer_data <- read_table("https://tofu.byu.edu/stat230/cancer.txt")
cancer_data %>%
group_by(type) %>%
summarize(mean(days), sd(days))
boxplot(cancer_data$days ~ cancer_data$type)
library(tidymodels)
install.packages("tidyverse")
install.packages("tidymodels")
bar_plot
library(tidyverse)
library(tidyverse)
library(tidymodels)
library(vroom)
data_csv <- vroom("train.csv")
setwd("~/Bike-Share")
library(tidyverse)
library(tidymodels)
library(vroom)
data_csv <- vroom("train.csv")
bar_plot <- ggplot(data_csv, aes(x = weather, y = count)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Counts of Each Weather Type",
x = "Category",
y = "Count") +
theme_minimal()
bar_plot
install.packages("DataExplorer")
library(DataExplorer)
library(DataExplorer)
correlations <- DataExplorer::plot_correlation(data = data_csv)
install.packages("skimr")
library(skimr)
overview <- skimr::skim(data_csv)
print(overview)
missing <- DataExplorer::plot_missing(data_csv)
glimpse <- dplyr::glimpse(data_csv)
hists <- DataExplorer::plot_histogram(data_csv)
(plot1 + plot2) / (plot1 + plot2)
hists <- DataExplorer::plot_histogram(data_csv)
glimpse <- dplyr::glimpse(data_csv)
(bar_plot + correlations) / (missing + hists)
hists <- DataExplorer::plot_histogram(data_csv, output = "ggplot")
?DataExplorer::plot_histogram
?DataExplorer::plot_missing
(bar_plot + missing)
average_per_weather <- data_csv |>
group_by(weather)
print(average_per_weather)
average_per_weather <- data_csv |>
group_by(weather) |>
summarize(mean_rentals = mean(count, na.rm = TRUE))
print(average_per_weather)
bar_plot <- ggplot(average_per_weather, aes(x = weather, y = mean_rentals)) +
geom_bar(fill = "steelblue") +
labs(title = "Counts of Each Weather Type",
x = "Category",
y = "Count") +
theme_minimal()
bar_plot
bar_plot <- ggplot(average_per_weather, aes(x = weather, y = mean_rentals)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Counts of Each Weather Type",
x = "Category",
y = "Count") +
theme_minimal()
bar_plot
View(data_csv)
temp_histogram <- ggplot(data, aes(x = temperature)) +
geom_histogram(binwidth = 5, fill = "steelblue", color = "white") +
labs(title = "Histogram of Temperatures By Hour",
x = "Temperature (°F)",
y = "Frequency") +
theme_minimal()
temp_histogram <- ggplot(data, aes(x = atemp)) +
geom_histogram(binwidth = 5, fill = "steelblue", color = "white") +
labs(title = "Histogram of Adjusted Temperatures By Hour",
x = "Temperature (°F)",
y = "Frequency") +
theme_minimal()
temp_histogram <- ggplot(data_csv, aes(x = atemp)) +
geom_histogram(binwidth = 5, fill = "steelblue", color = "white") +
labs(title = "Histogram of Adjusted Temperatures By Hour",
x = "Temperature (°F)",
y = "Frequency") +
theme_minimal()
temp_histogram
temp_histogram <- ggplot(data_csv, aes(x = atemp)) +
geom_histogram(binwidth = 5, fill = "steelblue", color = "white") +
labs(title = "Histogram of Adjusted Temperatures By Hour",
x = "Temperature (°C)",
y = "Frequency") +
theme_minimal()
temp_histogram
install.packages("GGally")
library(GGally)
library(ggally)
library(GGally)
ggally_correlations <- GGally::ggpairs(data_csv)
ggally_correlations
GGally::ggpairs(data_csv)
correlations_filtered <- data_csv |>
select(weather, temp, atemp, humidity)
GGally::ggpairs(correlations_filtered)
correlations_filtered <- data_csv |>
select(weather, temp, atemp, humidity, windspeed, count)
GGally::ggpairs(correlations_filtered)
(weather_bar_plot + temp_histogram)# / (plot1 + plot2)
weather_bar_plot <- ggplot(average_per_weather, aes(x = weather, y = mean_rentals)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Counts of Each Weather Type",
x = "Category",
y = "Count") +
theme_minimal()
(weather_bar_plot + temp_histogram)# / (plot1 + plot2)
rlang::last_trace()
(weather_bar_plot | temp_histogram)# / (plot1 + plot2)
library(patchwork)
(weather_bar_plot | temp_histogram)# / (plot1 + plot2)
(weather_bar_plot | correlations)# / (plot1 + plot2)
(weather_bar_plot | correlations) / (missing + hists)
library(tidyverse)
library(tidymodels)
library(DataExplorer)
library(GGally)
library(skimr)
library(vroom)
library(patchwork)
(plot1 + plot2) / (plot1 + plot2)
data_csv <- vroom("train.csv")
average_per_weather <- data_csv |>
group_by(weather) |>
summarize(mean_rentals = mean(count, na.rm = TRUE))
print(average_per_weather)
weather_bar_plot <- ggplot(average_per_weather, aes(x = weather, y = mean_rentals)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Counts of Each Weather Type By Hour",
x = "Category",
y = "Count") +
theme_minimal()
weather_bar_plot
temp_histogram <- ggplot(data_csv, aes(x = atemp)) +
geom_histogram(binwidth = 5, fill = "steelblue", color = "white") +
labs(title = "Histogram of Adjusted Temperatures By Hour",
x = "Temperature (°C)",
y = "Frequency") +
theme_minimal()
temp_histogram
correlations_filtered <- data_csv |>
select(weather, temp, atemp, humidity, windspeed, count)
GGally::ggpairs(correlations_filtered)
correlations <- DataExplorer::plot_correlation(data = data_csv)
missing <- DataExplorer::plot_missing(data_csv)
hists <- DataExplorer::plot_histogram(data_csv)
glimpse <- dplyr::glimpse(data_csv)
(weather_bar_plot | temp_histogram)# / (plot1 + plot2)
(weather_bar_plot | correlations) / (missing + hists)
View(average_per_weather)
library(tidyverse)
library(tidymodels)
train_data <- vroom("train.csv")
test_data <- vroom("test.csv")
## Setup and Fit the Linear Regression Model3
my_linear_model <- linear_reg() %>% #Type of model4
set_engine("lm") %>% # Engine = What R function to use5
set_mode("regression") %>% # Regression just means quantitative response6
fit(formula=count ~ .-datetime, data=train_data)
## Generate Predictions Using Linear Model9
bike_predictions <- predict(my_linear_model, new_data=testData) # Use fit to predict
## Setup and Fit the Linear Regression Model3
my_linear_model <- linear_reg() %>% #Type of model4
set_engine("lm") %>% # Engine = What R function to use5
set_mode("regression") %>% # Regression just means quantitative response6
fit(formula=count ~ .-datetime, data=train_data)
## Generate Predictions Using Linear Model9
bike_predictions <- predict(my_linear_model, new_data=test_data) # Use fit to predict
library(tidyverse)
library(tidymodels)
train_data <- vroom("train.csv")
test_data <- vroom("test.csv")
View(test_data)
train_data <- vroom("train.csv") |>
select(humidity)
test_data <- vroom("test.csv")
train_data <- vroom("train.csv") |>
select(-casual)
test_data <- vroom("test.csv")
View(train_data)
View(test_data)
View(train_data)
View(test_data)
View(train_data)
View(test_data)
View(train_data)
View(test_data)
train_data <- vroom("train.csv") |>
select(-casual, -registered)
test_data <- vroom("test.csv")
## Setup and Fit the Linear Regression Model3
my_linear_model <- linear_reg() %>% #Type of model4
set_engine("lm") %>% # Engine = What R function to use5
set_mode("regression") %>% # Regression just means quantitative response6
fit(formula=count ~ .-datetime, data=train_data)
## Generate Predictions Using Linear Model9
bike_predictions <- predict(my_linear_model, new_data=test_data) # Use fit to predict
bike_predictions ## Look at the output
## Format the Predictions for Submission to Kaggle
kaggle_submission <- bike_predictions %>%
bind_cols(., testData) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and prediction variables
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime)))
## Format the Predictions for Submission to Kaggle
kaggle_submission <- bike_predictions %>%
bind_cols(., test_data) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and prediction variables
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime)))
## Write out the file9
vroom_write(x=kaggle_submission, file="./LinearPreds.csv", delim=",")
